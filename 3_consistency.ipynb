{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "621c3842",
   "metadata": {},
   "source": [
    "# Measuring Consistency\n",
    "\n",
    "In this notebook, we evaluate the consistency of cluster assignments across various subsets of data.\n",
    "This ensures our model’s robustness, preventing over-sensitivity to particular data samples.\n",
    "Initially, we establish a baseline by applying BGMM to the entire dataset. We then partition\n",
    "the dataset into halves, thirds, and quarters, performing separate clustering on each subset.\n",
    "By merging these subset clustering results and comparing them with the original dataset’s\n",
    "clustering, we assess the solution’s stability. For each subset comparison, we calculate two\n",
    "metrics: Accuracy and ARI. The Accuracy of cluster comparisons is determined by the proportion of data points re-\n",
    "taining their original cluster assignments. The Adjusted Rand Index (ARI) is a metric\n",
    "that quantifies the similarity between two data clusterings and corrects for chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4385af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Relevant Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, adjusted_rand_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "\n",
    "# Reading in our Datasets\n",
    "df_1024 = pd.read_csv(\"data/1024_unscaled.csv\")\n",
    "df_1024_scaled = pd.read_csv(\"data/1024_scaled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18f6b120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(df, features):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_values = scaler.fit_transform(df[features])\n",
    "    df_scaled = pd.DataFrame(scaled_values, columns=features)\n",
    "    return df_scaled\n",
    "\n",
    "def fit_predict_model(model, data):\n",
    "    try:\n",
    "        labels = model.fit_predict(data)\n",
    "    except AttributeError:\n",
    "        model.fit(data)\n",
    "        labels = model.predict(data)\n",
    "    return labels\n",
    "\n",
    "def adjust_labels_by_size(labels, num_clusters):\n",
    "    # Count the occurrences of each label\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    label_counts = dict(zip(unique, counts))\n",
    "    \n",
    "    # Sort the labels by count (size)\n",
    "    sorted_labels = sorted(label_counts, key=label_counts.get)\n",
    "    \n",
    "    # Create a mapping from old to new labels based on size\n",
    "    label_mapping = {old_label: new_label for new_label, old_label in enumerate(sorted_labels)}\n",
    "    \n",
    "    # Adjust labels based on the mapping\n",
    "    adjusted_labels = np.array([label_mapping[label] for label in labels])\n",
    "    \n",
    "    return adjusted_labels\n",
    "\n",
    "\n",
    "def process_splits(model, df, features, n_splits, num_clusters):\n",
    "    split_size = int(len(df) / n_splits)\n",
    "    df_splits = [df[i*split_size:(i+1)*split_size].copy() for i in range(n_splits)]\n",
    "    df_splits[-1] = df[(n_splits-1)*split_size:].copy()  # Include any leftover rows in the last split\n",
    "    \n",
    "    combined_labels = pd.Series(index=df.index, dtype='int')\n",
    "    \n",
    "    for df_split in df_splits:\n",
    "        df_split_scaled = scale_data(df_split, features)\n",
    "        labels = fit_predict_model(model, df_split_scaled)\n",
    "        adjusted_labels = adjust_labels_by_size(labels, num_clusters)\n",
    "        combined_labels.loc[df_split.index] = adjusted_labels\n",
    "    \n",
    "    return combined_labels\n",
    "\n",
    "\n",
    "def calculate_accuracy(num_clusters, model_name):\n",
    "    features = ['LSI_all', 'zeta_all', 'd5_all', 'Sk_all', 'q_all', 'Q6_all']\n",
    "    \n",
    "    model_mapping = {\n",
    "        'BGMM': BayesianGaussianMixture(covariance_type=\"full\", n_components=num_clusters),\n",
    "        'KMeans': KMeans(n_clusters=num_clusters),\n",
    "        'AgglomerativeClustering': AgglomerativeClustering(n_clusters=num_clusters),\n",
    "        'DBSCAN': DBSCAN()  # DBSCAN doesn't require specifying the number of clusters\n",
    "    }\n",
    "    \n",
    "    model = model_mapping[model_name]  # Change this line to use different models\n",
    "    df_1024_scaled_labels = fit_predict_model(model, scale_data(df_1024_scaled, features))\n",
    "    df_1024_scaled['labels'] = adjust_labels_by_size(df_1024_scaled_labels, num_clusters)\n",
    "    \n",
    "    for n_splits in [2, 3, 4]:\n",
    "        labels = process_splits(model, df_1024_scaled, features, n_splits, num_clusters)\n",
    "        accuracy = accuracy_score(df_1024_scaled['labels'], labels)\n",
    "        ari = adjusted_rand_score(df_1024_scaled['labels'], labels)\n",
    "        print(f\"Accuracy for {n_splits} splits:\", accuracy)\n",
    "        print(f\"ARI for {n_splits} splits:\", ari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5581e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 2 splits: 0.9996124441964286\n",
      "ARI for 2 splits: 0.9983479415621945\n",
      "Accuracy for 3 splits: 0.999588123139881\n",
      "ARI for 3 splits: 0.9982443552822808\n",
      "Accuracy for 4 splits: 0.9995329241071429\n",
      "ARI for 4 splits: 0.9980092217891083\n"
     ]
    }
   ],
   "source": [
    "# measuring consistency of BGMM applied to 2 clusters\n",
    "calculate_accuracy(2, \"BGMM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a73c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c6d7c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
