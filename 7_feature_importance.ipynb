{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "565ec4ad",
   "metadata": {},
   "source": [
    "# Feature Importance\n",
    "\n",
    "In this notebook, we measure Feature Importance through four different metrics: \n",
    "- Explained Variance of our Bayesian Gaussian Mixture Model\n",
    "- Permuted Change in the Bayesian Information Criterion (BIC) Score\n",
    "- Random Forest Feature Importance\n",
    "- Mutual Information Score for Classification\n",
    "In the end, we standardise each metric and combine the scores together to form a final Feature Importance score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5132a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Relevant Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d15d104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the scaled and unscaled versions of the 1024 molecule data\n",
    "df_1024 = pd.read_csv(\"data/1024_unscaled.csv\")\n",
    "df_1024_scaled = pd.read_csv(\"data/1024_scaled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8a6386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the BGMM Model on our dataset\n",
    "features = ['Sk_all','LSI_all','zeta_all', 'q_all', 'Q6_all', 'd5_all']\n",
    "gmm = BayesianGaussianMixture(covariance_type=\"full\",\n",
    "                              n_components=2,\n",
    "                              tol=1e-3,\n",
    "                              max_iter=200,\n",
    "                              mean_precision_prior=None,\n",
    "                              weight_concentration_prior=None)\n",
    "gmm.fit(df_1024_scaled[features])\n",
    "labels = gmm.predict(df_1024_scaled[features])\n",
    "\n",
    "# Adjust labels so 0 is the larger cluster\n",
    "zero_count = (labels == 0).sum()\n",
    "one_count = (labels == 1).sum()\n",
    "if zero_count < one_count:\n",
    "    labels = 1 - labels  # This flips 0s to 1s and 1s to 0s\n",
    "df_1024_scaled['labels'] = labels\n",
    "\n",
    "X = df_1024_scaled[['Sk_all','LSI_all','zeta_all', 'q_all', 'Q6_all', 'd5_all']]\n",
    "n_components = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968a3189",
   "metadata": {},
   "source": [
    "# Explained Variance\n",
    "The explained variance for each feature is the weighted sum of the variances of the feature's values across all the Gaussian components (or clusters). A higher explained variance for a feature means that this feature plays a significant role in differentiating between the components (or clusters) in the model. Conversely, a lower explained variance indicates that the feature does not contribute much to the overall structure captured by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b89f5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d5_all': 0.29446726850933036, 'Q6_all': 0.230576323274261, 'q_all': 0.20745303735819598, 'zeta_all': 0.11114752210450479, 'Sk_all': 0.08944442699178166, 'LSI_all': 0.06691142176192612}\n"
     ]
    }
   ],
   "source": [
    "explained_variance = np.zeros(X.shape[1])\n",
    "\n",
    "for component in range(n_components):\n",
    "    # Calculate the variance explained by each component\n",
    "    component_variance = np.var(X - gmm.means_[component], axis=0)\n",
    "    explained_variance += gmm.weights_[component] * component_variance\n",
    "\n",
    "# Normalize explained variance to sum to 1 for interpretation\n",
    "explained_variance /= np.sum(explained_variance)\n",
    "\n",
    "explained_variance=explained_variance.sort_values(ascending=False)\n",
    "explained_variance=explained_variance.to_dict()\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7862070",
   "metadata": {},
   "source": [
    "# Permuted Change in BIC Score\n",
    "The BIC score is a metric that addresses the trade-off between model fit and complexity, assessing how well the model explains the observed data while penalizing models that are overly complex. We apply the concept of permutation importance to the change in BIC score by randomly permuting each individual feature and assessing the BIC score of the resultant model when compared to the original. A substantial change in the BIC score after permuting a feature suggests that the feature is important, as it significantly influences the model’s performance. Conversely, if the BIC score remains relatively unchanged, it indicates that the feature has a limited role in determining the clustering structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "762daa34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Ranking based on Permutation Importance with BIC:\n",
      "{'zeta_all': 0.646148517890445, 'd5_all': 0.6357782875765131, 'LSI_all': 0.4502411126967725, 'Sk_all': 0.38044228107657824, 'q_all': 0.19929059669334176, 'Q6_all': 0.0013903515146025983}\n"
     ]
    }
   ],
   "source": [
    "bic_scores = {}\n",
    "def custom_metric(model, data):\n",
    "    # Calculate BIC manually for each permutation\n",
    "    log_likelihood = model.score_samples(data)\n",
    "    n_samples, n_features = data.shape\n",
    "    k = n_components * (2 * n_features + 1)  # Number of parameters in the model\n",
    "    bic = -2 * np.sum(log_likelihood) + k * np.log(n_samples)\n",
    "    return bic\n",
    "\n",
    "# If X is a NumPy array, you should have a list of feature names as well\n",
    "feature_names = X.columns.tolist()  # Replace X.columns with the actual column accessor if needed\n",
    "\n",
    "# Calculate permutation-based feature importances using BIC\n",
    "perm_importance = permutation_importance(gmm, X, custom_metric, n_repeats=30, random_state=42)\n",
    "\n",
    "# Rank features based on the difference in BIC values\n",
    "sorted_features = np.argsort(perm_importance.importances_mean)[::-1]\n",
    "\n",
    "# Print the ranking of features based on importance along with feature names\n",
    "print(\"Feature Ranking based on Permutation Importance with BIC:\")\n",
    "for rank, feature_idx in enumerate(sorted_features):\n",
    "    feature_name = feature_names[feature_idx]\n",
    "    bic_scores[feature_name]=perm_importance.importances_mean[feature_idx]\n",
    "print(bic_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a8566a",
   "metadata": {},
   "source": [
    "# Random Forest Feature Importance\n",
    "In a Random Forest, which is an ensemble of decision trees, the significance of each feature is gauged by its contribution to reducing the impurity in these nodes. Impurity in a decision tree context refers to the diversity of class labels within a node. A node is 'pure' (with zero impurity) when all its samples belong to the same class, or cluster in this case. To compute feature importance in Random Forests, we assess the decrease in impurity attributable to each feature. A higher RFI score indicates that the feature significantly influences the model’s decision-making process, underlining its importance in predicting the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c93331a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSI_all     0.452972\n",
      "Sk_all      0.301161\n",
      "zeta_all    0.124863\n",
      "d5_all      0.100934\n",
      "q_all       0.017076\n",
      "Q6_all      0.002993\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Convert to NumPy array if X is a DataFrame\n",
    "X_array = X.values if isinstance(X, pd.DataFrame) else X\n",
    "\n",
    "# Initialize and train the classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_array, labels)\n",
    "\n",
    "# Extract and display feature importances\n",
    "importances = rf.feature_importances_\n",
    "feature_names = X.columns if isinstance(X, pd.DataFrame) else [f\"Feature {i}\" for i in range(X_array.shape[1])]\n",
    "feature_importances = pd.Series(importances, index=feature_names)\n",
    "print(feature_importances.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c93fbb",
   "metadata": {},
   "source": [
    "# Mutual Information Score for Classification\n",
    "Mutual Information Score is an important metric in classification tasks, particularly valuable for quantifying the relationship between continuous features (the order parameters) and a discrete target variable, such as the state of a water molecule which is binary (represented as clusters 0 and 1). This score measures the amount of information shared between a continuous feature and the binary target, effectively quantifying the reduction in uncertainty about the class label given the feature's value. A higher Mutual Information Score indicates that knowledge of feature x greatly reduces uncertainty about the target y, highlighting its significance in the classification task.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46fa9522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSI_all     0.273289\n",
      "Sk_all      0.142949\n",
      "zeta_all    0.128553\n",
      "d5_all      0.128103\n",
      "q_all       0.000864\n",
      "Q6_all      0.000085\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Convert to NumPy array if X is a DataFrame\n",
    "X_array = X.values if isinstance(X, pd.DataFrame) else X\n",
    "feature_names = X.columns if isinstance(X, pd.DataFrame) else [f\"Feature {i}\" for i in range(X_array.shape[1])]\n",
    "\n",
    "# Calculate mutual information\n",
    "mi_scores = mutual_info_classif(X_array, labels)\n",
    "\n",
    "# Display mutual information scores\n",
    "mi_scores_series = pd.Series(mi_scores, index=feature_names)\n",
    "print(mi_scores_series.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35106095",
   "metadata": {},
   "source": [
    "Before combining the different metrics (explained variance, BIC scores, feature importances, and mutual information scores) for each feature, it is essential to standardise these series. Standardisation involves rescaling the distributions of values so that they have a mean of zero and a standard deviation of one. This process is crucial because each metric may have different scales and ranges. By standardising, we ensure that each metric contributes equally to the final score, avoiding bias towards any particular metric due to its scale. The scores are then averaged to obtain a comprehensive view of each feature's relative importance across all metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1434d844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">ExplainedVariance</th>\n",
       "      <th colspan=\"2\" halign=\"left\">BIC</th>\n",
       "      <th colspan=\"2\" halign=\"left\">FeatureImportances</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MIScores</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Standardized</th>\n",
       "      <th>Value</th>\n",
       "      <th>Standardized</th>\n",
       "      <th>Value</th>\n",
       "      <th>Standardized</th>\n",
       "      <th>Value</th>\n",
       "      <th>Standardized</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LSI_all</th>\n",
       "      <td>0.066911</td>\n",
       "      <td>-1.100570</td>\n",
       "      <td>0.450241</td>\n",
       "      <td>0.256924</td>\n",
       "      <td>0.452972</td>\n",
       "      <td>1.624565</td>\n",
       "      <td>0.273289</td>\n",
       "      <td>1.572805</td>\n",
       "      <td>0.449642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d5_all</th>\n",
       "      <td>0.294467</td>\n",
       "      <td>1.409986</td>\n",
       "      <td>0.635778</td>\n",
       "      <td>0.993777</td>\n",
       "      <td>0.100934</td>\n",
       "      <td>-0.372980</td>\n",
       "      <td>0.128103</td>\n",
       "      <td>0.154329</td>\n",
       "      <td>0.418049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zeta_all</th>\n",
       "      <td>0.111148</td>\n",
       "      <td>-0.612526</td>\n",
       "      <td>0.646149</td>\n",
       "      <td>1.034962</td>\n",
       "      <td>0.124863</td>\n",
       "      <td>-0.237202</td>\n",
       "      <td>0.128553</td>\n",
       "      <td>0.158727</td>\n",
       "      <td>0.169334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sk_all</th>\n",
       "      <td>0.089444</td>\n",
       "      <td>-0.851970</td>\n",
       "      <td>0.380442</td>\n",
       "      <td>-0.020279</td>\n",
       "      <td>0.301161</td>\n",
       "      <td>0.763153</td>\n",
       "      <td>0.142949</td>\n",
       "      <td>0.299371</td>\n",
       "      <td>0.138034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q_all</th>\n",
       "      <td>0.207453</td>\n",
       "      <td>0.449984</td>\n",
       "      <td>0.199291</td>\n",
       "      <td>-0.739715</td>\n",
       "      <td>0.017076</td>\n",
       "      <td>-0.848813</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>-1.088811</td>\n",
       "      <td>-0.225334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q6_all</th>\n",
       "      <td>0.230576</td>\n",
       "      <td>0.705096</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>-1.525668</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>-0.928722</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>-1.096421</td>\n",
       "      <td>-0.326334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ExplainedVariance                    BIC               \\\n",
       "                     Value Standardized     Value Standardized   \n",
       "Feature                                                          \n",
       "LSI_all           0.066911    -1.100570  0.450241     0.256924   \n",
       "d5_all            0.294467     1.409986  0.635778     0.993777   \n",
       "zeta_all          0.111148    -0.612526  0.646149     1.034962   \n",
       "Sk_all            0.089444    -0.851970  0.380442    -0.020279   \n",
       "q_all             0.207453     0.449984  0.199291    -0.739715   \n",
       "Q6_all            0.230576     0.705096  0.001390    -1.525668   \n",
       "\n",
       "         FeatureImportances               MIScores                Average  \n",
       "                      Value Standardized     Value Standardized            \n",
       "Feature                                                                    \n",
       "LSI_all            0.452972     1.624565  0.273289     1.572805  0.449642  \n",
       "d5_all             0.100934    -0.372980  0.128103     0.154329  0.418049  \n",
       "zeta_all           0.124863    -0.237202  0.128553     0.158727  0.169334  \n",
       "Sk_all             0.301161     0.763153  0.142949     0.299371  0.138034  \n",
       "q_all              0.017076    -0.848813  0.000864    -1.088811 -0.225334  \n",
       "Q6_all             0.002993    -0.928722  0.000085    -1.096421 -0.326334  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert dictionaries to pandas DataFrames\n",
    "df_explained_variance = pd.DataFrame(list(explained_variance.items()), columns=['Feature', 'Value'])\n",
    "df_bic_scores = pd.DataFrame(list(bic_scores.items()), columns=['Feature', 'Value'])\n",
    "df_feature_importances = pd.DataFrame(list(feature_importances.items()), columns=['Feature', 'Value'])\n",
    "df_mi_scores = pd.DataFrame(list(mi_scores_series.items()), columns=['Feature', 'Value'])\n",
    "\n",
    "# Function to standardize a dataframe\n",
    "def standardize(df):\n",
    "    df['Standardized'] = (df['Value'] - df['Value'].mean()) / df['Value'].std()\n",
    "    return df\n",
    "\n",
    "# Standardize each DataFrame\n",
    "df_explained_variance_std = standardize(df_explained_variance)\n",
    "df_bic_scores_std = standardize(df_bic_scores)\n",
    "df_feature_importances_std = standardize(df_feature_importances)\n",
    "df_mi_scores_std = standardize(df_mi_scores)\n",
    "\n",
    "# Combine the standardized scores by averaging\n",
    "combined_std = pd.concat([df_explained_variance_std.set_index('Feature'), df_bic_scores_std.set_index('Feature'),\n",
    "                          df_feature_importances_std.set_index('Feature'), df_mi_scores_std.set_index('Feature')],\n",
    "                         axis=1, keys=['ExplainedVariance', 'BIC', 'FeatureImportances', 'MIScores'])\n",
    "\n",
    "# Average the standardized scores\n",
    "combined_std['Average'] = combined_std.mean(axis=1)\n",
    "\n",
    "combined_std.sort_values('Average', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26306bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6ce19e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbf9c21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
